# 针对单卡RTX 3080 的调试优化配置
# 重点：利用现代GPU特性 (TF32, BF16, Flash Attention)，快速迭代调试

wandb:
  project: "ESM2AE-3080-Debug"
  resume: "allow"
  tags: ["3080", "single_gpu", "debug", "modern_features"]

trainer:
  output_dir: "/home/zhaolab/DataHD/AX/ESM2AE/checkpoint"
  save_strategy: "steps"
  save_steps: 500  # 调试时更频繁保存
  learning_rate: 1.5e-4  # 较高学习率，利用更大批次
  per_device_train_batch_size: 20  # 3080可以支持更大批次
  per_device_eval_batch_size: 40
  num_train_epochs: 100
  seed: 42
  data_seed: 42
  dataloader_num_workers: 12  # 3080配置通常CPU更强
  dataloader_prefetch_factor: 4
  dataloader_pin_memory: true  # 3080有足够内存支持pin memory
  dataloader_drop_last: true
  logging_dir: "/home/zhaolab/DataHD/AX/ESM2AE/logs"
  
  # 3080现代特性支持
  tf32: true  # 启用TF32获得更好的性能
  fp16: false  # 使用BF16替代FP16
  bf16: true  # BF16提供更好的数值稳定性
  
  push_to_hub: false
  report_to: "wandb"
  weight_decay: 1e-4
  adam_beta1: 0.9
  adam_beta2: 0.95
  adam_epsilon: 1e-8
  save_safetensors: true
  greater_is_better: false
  load_best_model_at_end: false
  optim: "adamw_torch_fused"  # 使用fused优化器
  gradient_accumulation_steps: 2  # 调试时减少累积步数以便快速反馈
  metric_for_best_model: "train_loss"
  logging_steps: 20  # 调试时更频繁的日志
  warmup_ratio: 0.05
  lr_scheduler_type: "cosine"
  save_total_limit: 5  # 调试时保留更多检查点
  max_steps: -1
  eval_steps: 1000
  evaluation_strategy: "no"
  
  # 性能优化设置
  group_by_length: true
  length_column_name: "length"
  remove_unused_columns: false
  prediction_loss_only: true
  skip_memory_metrics: false  # 调试时监控内存
  
  # 梯度和优化设置
  max_grad_norm: 1.0
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false  # 使用更现代的检查点实现
  
  # I/O优化
  dataloader_persistent_workers: true  # 3080环境支持持久worker

data:
  train_path: "/home/zhaolab/DataHD/AX/ESM2AE/dataset"
  cache_dir: "/home/zhaolab/DataHD/AX/ESM2AE/tokenizer_cache"
  max_length: 512  # 3080可以支持更长序列
  batch_size: 2000
  preprocessing_num_proc: 8

model:
  pretrained_model_name: "facebook/esm2_t33_650M_UR50D"
  attn_implementation: "flash_attention_2"  # 3080支持Flash Attention 2
  position_embedding_type: "rotary"
  num_labels: 1
  problem_type: "regression"
  
  # 模型优化设置
  freeze_backbone: false
  use_feature_cache: true  # 调试时可以启用缓存
  
  # 数据类型设置
  torch_dtype: "bfloat16"  # 使用bfloat16

ray:
  num_workers: 1  # 单卡配置
  use_gpu: true
  
  # 单卡资源配置
  resources_per_worker:
    CPU: 16  # 3080环境通常CPU资源更充足
    GPU: 1
  
  # 单卡不需要复杂的分布式配置
  scaling_config:
    placement_strategy: "PACK"

deepspeed:
  config_path: "/home/zhaolab/DataHD/AX/ESM2AE/train_config/ZERO2_3080.yaml"

# 性能监控 - 调试模式
performance:
  monitor_gpu_usage: true
  monitor_memory_usage: true
  profile_data_loading: true  # 调试时启用数据加载分析
  benchmark_mode: false
  
# 3080特定优化
hardware_specific:
  gpu_model: "RTX_3080"
  memory_gb: 10  # 或12GB取决于具体型号
  nvlink: false  # 单卡无需NVLink
  compute_capability: "8.6"
  tensor_cores: "3rd_gen"
  
  # 现代特性支持
  modern_features:
    tf32_enabled: true
    bf16_enabled: true
    flash_attention: true
    fused_kernels: true
  
  # 内存管理 - 相对宽松
  memory_strategy:
    empty_cache_frequency: 200  # 较少的缓存清理频率
    gc_frequency: 500
    max_memory_fraction: 0.90  # 可以使用更多显存

# 调试特定配置
debug:
  # 快速验证设置
  fast_dev_run: false  # 设为true时只运行几个batch用于快速测试
  overfit_batches: 0  # 设为小数值时用于过拟合测试
  
  # 调试输出
  verbose_logging: true
  save_intermediate_outputs: false  # 调试时可保存中间输出
  
  # 性能分析
  profile_steps: [100, 200, 300]  # 在这些步骤进行性能分析
  memory_snapshot_steps: [50, 150, 250]  # 内存快照步骤